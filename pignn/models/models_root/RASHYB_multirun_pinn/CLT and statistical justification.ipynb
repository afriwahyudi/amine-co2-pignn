{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup paths\n",
    "runtyp = 'RASHYB_multirun_pinn'\n",
    "current_directory = os.getcwd()\n",
    "working_dir = os.path.dirname(current_directory)\n",
    "csv_directory = f\"{working_dir}/{runtyp}/metric_csv\"\n",
    "\n",
    "# Load all CSV files\n",
    "csv_files = glob.glob(os.path.join(csv_directory, \"*.csv\"))\n",
    "all_results = []\n",
    "\n",
    "for file_path in csv_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    parts = filename.replace('.csv', '').split('_')\n",
    "    \n",
    "    try:\n",
    "        seed = int(parts[1])\n",
    "        timestamp = parts[2] + '_' + parts[3]\n",
    "    except:\n",
    "        seed = None\n",
    "        timestamp = filename\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    df['filename'] = filename\n",
    "    df['seed'] = seed\n",
    "    df['model_id'] = f\"model_{seed}_{timestamp}\"\n",
    "    \n",
    "    all_results.append(df)\n",
    "\n",
    "# Combine all results\n",
    "combined_df = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# Calculate metrics for each model\n",
    "model_scores = []\n",
    "\n",
    "for model_id in combined_df['model_id'].unique():\n",
    "    model_data = combined_df[combined_df['model_id'] == model_id]\n",
    "    \n",
    "    # Get metrics for all datasets\n",
    "    train_rmse = model_data[model_data['Dataset'] == 'Training']['RMSE'].iloc[0]\n",
    "    train_r2 = model_data[model_data['Dataset'] == 'Training']['R2'].iloc[0]\n",
    "    val_rmse = model_data[model_data['Dataset'] == 'Validation']['RMSE'].iloc[0]\n",
    "    val_r2 = model_data[model_data['Dataset'] == 'Validation']['R2'].iloc[0]\n",
    "    test_rmse = model_data[model_data['Dataset'] == 'Test']['RMSE'].iloc[0]\n",
    "    test_r2 = model_data[model_data['Dataset'] == 'Test']['R2'].iloc[0]\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    generalization_gap = abs(train_rmse - val_rmse)\n",
    "    overall_rmse = (train_rmse + val_rmse) / 2\n",
    "    overall_r2 = (train_r2 + val_r2) / 2\n",
    "    \n",
    "    model_scores.append({\n",
    "        'model_id': model_id,\n",
    "        'seed': model_data['seed'].iloc[0],\n",
    "        'train_rmse': train_rmse,\n",
    "        'train_r2': train_r2,\n",
    "        'val_rmse': val_rmse,\n",
    "        'val_r2': val_r2,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_r2': test_r2,\n",
    "        'generalization_gap': generalization_gap,\n",
    "        'overall_rmse': overall_rmse,\n",
    "        'overall_r2': overall_r2\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "scores_df = pd.DataFrame(model_scores)\n",
    "\n",
    "print(f\"Total models analyzed: {len(scores_df)}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def demonstrate_central_limit_theorem(scores_df):\n",
    "    \"\"\"\n",
    "    Demonstrate Central Limit Theorem by showing how sampling distributions\n",
    "    evolve as sample size increases\n",
    "    \"\"\"\n",
    "    print(\"\\nDEMONSTRATING CENTRAL LIMIT THEOREM\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Randomly shuffle the data to simulate progressive sampling\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    shuffled_df = scores_df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # Key metrics to analyze\n",
    "    metrics = ['val_rmse', 'test_rmse', 'val_r2', 'generalization_gap']\n",
    "    metric_labels = ['Validation RMSE', 'Test RMSE', 'Validation R²', 'Generalization Gap']\n",
    "    \n",
    "    # Sample sizes to analyze (every 10 runs)\n",
    "    sample_sizes = list(range(10, len(shuffled_df) + 1, 10))\n",
    "    \n",
    "    # Store results for each sample size\n",
    "    sampling_results = {metric: {} for metric in metrics}\n",
    "    \n",
    "    for sample_size in sample_sizes:\n",
    "        current_sample = shuffled_df.iloc[:sample_size]\n",
    "        \n",
    "        for metric in metrics:\n",
    "            values = current_sample[metric].values\n",
    "            sampling_results[metric][sample_size] = {\n",
    "                'mean': np.mean(values),\n",
    "                'std': np.std(values, ddof=1),  # Sample standard deviation\n",
    "                'sem': np.std(values, ddof=1) / np.sqrt(sample_size),  # Standard Error of Mean\n",
    "                'values': values,\n",
    "                'n': sample_size\n",
    "            }\n",
    "    \n",
    "    return sampling_results, sample_sizes, shuffled_df\n",
    "\n",
    "def plot_clt_evolution(sampling_results, sample_sizes):\n",
    "    \"\"\"\n",
    "    Create separate figures for each metric showing CLT evolution with 6 subplots (every 10 models)\n",
    "    \"\"\"\n",
    "    metrics = list(sampling_results.keys())\n",
    "    metric_labels = ['Validation RMSE', 'Test RMSE', 'Validation R²', 'Generalization Gap']\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    # Select 6 sample sizes for visualization (every 10 models)\n",
    "    selected_sizes = []\n",
    "    for i in range(0, len(sample_sizes), max(1, len(sample_sizes)//6)):\n",
    "        selected_sizes.append(sample_sizes[i])\n",
    "    \n",
    "    # Ensure we have exactly 6 sizes (adjust if needed)\n",
    "    if len(selected_sizes) < 6 and len(sample_sizes) >= 6:\n",
    "        # Distribute evenly across the range\n",
    "        indices = np.linspace(0, len(sample_sizes)-1, 6, dtype=int)\n",
    "        selected_sizes = [sample_sizes[i] for i in indices]\n",
    "    elif len(selected_sizes) > 6:\n",
    "        selected_sizes = selected_sizes[:6]\n",
    "    \n",
    "    # Add the final size if it's not already included\n",
    "    if sample_sizes[-1] not in selected_sizes:\n",
    "        selected_sizes[-1] = sample_sizes[-1]\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, 6))\n",
    "    \n",
    "    # Create separate figure for each metric\n",
    "    for metric_idx, (metric, label) in enumerate(zip(metrics, metric_labels)):\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        # Calculate global range for consistent axes across subplots\n",
    "        all_values = []\n",
    "        for size in selected_sizes:\n",
    "            if size in sampling_results[metric]:\n",
    "                all_values.extend(sampling_results[metric][size]['values'])\n",
    "        \n",
    "        x_min_global, x_max_global = np.min(all_values), np.max(all_values)\n",
    "        x_range_global = x_max_global - x_min_global\n",
    "        \n",
    "\n",
    "        for i, (sample_size, color) in enumerate(zip(selected_sizes, colors)):\n",
    "            if sample_size in sampling_results[metric]:\n",
    "                ax = axes[i]\n",
    "                values = sampling_results[metric][sample_size]['values']\n",
    "                \n",
    "                if len(values) > 1:\n",
    "                    # Calculate histogram\n",
    "                    n_bins = min(15, max(6, len(values)//3))\n",
    "                    \n",
    "                    # Plot histogram\n",
    "                    counts, bins, patches = ax.hist(values, bins=n_bins, density=True, \n",
    "                                                  alpha=0.7, color=color, \n",
    "                                                  edgecolor='black', linewidth=0.8)\n",
    "                    \n",
    "                    # Fit normal distribution\n",
    "                    mu, sigma = stats.norm.fit(values)\n",
    "                    \n",
    "                    # Create smooth x-axis for the fitted normal curve\n",
    "                    x_smooth = np.linspace(x_min_global - 0.1*x_range_global, \n",
    "                                         x_max_global + 0.1*x_range_global, 200)\n",
    "                    \n",
    "                    # Calculate and plot normal distribution curve\n",
    "                    normal_curve = stats.norm.pdf(x_smooth, mu, sigma)\n",
    "                    ax.plot(x_smooth, normal_curve, 'r-', linewidth=3, alpha=0.8,\n",
    "                           label='Normal fit')\n",
    "                    \n",
    "                    # Add mean line\n",
    "                    ax.axvline(mu, color='red', linestyle='--', alpha=0.8, linewidth=2, label=f'Mean μ')\n",
    "                    ax.legend() \n",
    "                    \n",
    "                    # Formatting\n",
    "                    ax.set_xlabel(label, fontsize=16)\n",
    "                    ax.set_ylabel('Density', fontsize=16)\n",
    "                    ax.set_title(f'n = {sample_size} models\\n(μ = {mu:.4f}, σ = {sigma:.4f})', \n",
    "                               fontsize=16)\n",
    "                    ax.tick_params(axis='x', labelsize=16)\n",
    "                    ax.tick_params(axis='y', labelsize=16)\n",
    "                    ax.grid(False)\n",
    "                    ax.legend(fontsize=16)\n",
    "                    \n",
    "                    # Set consistent x-axis limits\n",
    "                    ax.set_xlim(x_min_global - 0.05*x_range_global, \n",
    "                               x_max_global + 0.05*x_range_global)\n",
    "                               \n",
    "                    ax.set_ylim(0, 50)  # Add 10% padding\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    # 3. SAMPLING DISTRIBUTION OF MEANS\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    for i, (metric, label) in enumerate(zip(metrics, metric_labels)):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        means = [sampling_results[metric][n]['mean'] for n in sample_sizes]\n",
    "        sems = [sampling_results[metric][n]['sem'] for n in sample_sizes]\n",
    "        \n",
    "        ax.errorbar(sample_sizes, means, yerr=sems, fmt='o',\n",
    "                linewidth=2, markersize=6, capsize=5,\n",
    "                label='Sample Mean ± SEM')\n",
    "        \n",
    "        population_mean = means[-1]\n",
    "        ax.axhline(y=population_mean, color='red', linestyle='--', linewidth=2,\n",
    "                  label=f'Population Mean ≈ {population_mean:.4f}')\n",
    "        \n",
    "        population_std = sampling_results[metric][sample_sizes[-1]]['std']\n",
    "        theoretical_sems = [population_std / np.sqrt(n) for n in sample_sizes]\n",
    "        ax.plot(sample_sizes, np.array(means[-1]) + np.array(theoretical_sems), \n",
    "               'g:', alpha=0.7, linewidth=2, label='Theoretical ±SEM')\n",
    "        ax.plot(sample_sizes, np.array(means[-1]) - np.array(theoretical_sems), \n",
    "               'g:', alpha=0.7, linewidth=2)\n",
    "        \n",
    "        ax.set_xlabel('Model count (n)', fontsize=12)\n",
    "        ax.set_ylabel(f'Sample Mean of {label}', fontsize=12)\n",
    "        ax.set_title(f'Central Limit Theorem: {label}', fontsize=14, fontweight='bold')\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        final_sem = sems[-1]\n",
    "        reduction_factor = sems[0] / final_sem\n",
    "        info_text = f'SEM Reduction: {reduction_factor:.1f}×\\nFinal SEM: {final_sem:.4f}'\n",
    "        ax.text(0.02, 0.98, info_text, transform=ax.transAxes, fontsize=10,\n",
    "               verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_clt_summary_table(sampling_results, sample_sizes):\n",
    "    \"\"\"\n",
    "    Create summary table showing CLT progression\n",
    "    \"\"\"\n",
    "    summary_data = []\n",
    "    \n",
    "    for n in sample_sizes:\n",
    "        row = {'sample_size': n}\n",
    "        for metric in sampling_results.keys():\n",
    "            data = sampling_results[metric][n]\n",
    "            row[f'{metric}_mean'] = data['mean']\n",
    "            row[f'{metric}_sem'] = data['sem']\n",
    "            row[f'{metric}_std'] = data['std']\n",
    "        summary_data.append(row)\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    print(f\"\\nCENTRAL LIMIT THEOREM PROGRESSION\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'n':<4} {'Val RMSE':<15} {'SEM':<10} {'Test RMSE':<15} {'SEM':<10}\")\n",
    "    print(f\"{'Size':<4} {'Mean±SEM':<15} {'Reduction':<10} {'Mean±SEM':<15} {'Reduction':<10}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    initial_val_sem = summary_df.iloc[0]['val_rmse_sem']\n",
    "    initial_test_sem = summary_df.iloc[0]['test_rmse_sem']\n",
    "    \n",
    "    for _, row in summary_df.iterrows():\n",
    "        val_sem_reduction = initial_val_sem / row['val_rmse_sem']\n",
    "        test_sem_reduction = initial_test_sem / row['test_rmse_sem']\n",
    "        \n",
    "        print(f\"{int(row['sample_size']):<4} \"\n",
    "              f\"{row['val_rmse_mean']:.4f}±{row['val_rmse_sem']:.4f}  \"\n",
    "              f\"{val_sem_reduction:.1f}×       \"\n",
    "              f\"{row['test_rmse_mean']:.4f}±{row['test_rmse_sem']:.4f}  \"\n",
    "              f\"{test_sem_reduction:.1f}×\")\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# Run CLT analysis\n",
    "sampling_results, sample_sizes, shuffled_df = demonstrate_central_limit_theorem(scores_df)\n",
    "\n",
    "# Generate all CLT visualizations\n",
    "print(\"\\nGenerating Central Limit Theorem visualizations...\")\n",
    "plot_clt_evolution(sampling_results, sample_sizes)\n",
    "\n",
    "# Create summary table\n",
    "summary_df = create_clt_summary_table(sampling_results, sample_sizes)\n",
    "\n",
    "# Display overall data summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OVERALL DATA SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nALL {len(scores_df)} MODELS SUMMARY:\")\n",
    "print(\"-\" * 40)\n",
    "for dataset in ['Training', 'Validation', 'Test']:\n",
    "    subset = combined_df[combined_df['Dataset'] == dataset]\n",
    "    r2_mean = subset['R2'].mean()\n",
    "    r2_std = subset['R2'].std()\n",
    "    rmse_mean = subset['RMSE'].mean()\n",
    "    rmse_std = subset['RMSE'].std()\n",
    "    print(f\"{dataset:12} | R²: {r2_mean:.4f}±{r2_std:.4f} | RMSE: {rmse_mean:.4f}±{rmse_std:.4f}\")\n",
    "\n",
    "# Final CLT insights\n",
    "print(f\"\\nCENTRAL LIMIT THEOREM INSIGHTS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "final_val_sem = sampling_results['val_rmse'][sample_sizes[-1]]['sem']\n",
    "initial_val_sem = sampling_results['val_rmse'][sample_sizes[0]]['sem']\n",
    "sem_improvement = initial_val_sem / final_val_sem\n",
    "\n",
    "print(f\"Standard Error of Mean reduction: {sem_improvement:.1f}× (from {initial_val_sem:.4f} to {final_val_sem:.4f})\")\n",
    "print(f\"This demonstrates that with {len(scores_df)} runs, our mean estimates are\")\n",
    "print(f\"{sem_improvement:.1f}× more precise than with just {sample_sizes[0]} runs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pignn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
