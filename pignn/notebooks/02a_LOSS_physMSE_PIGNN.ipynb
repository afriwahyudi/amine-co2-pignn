{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARY IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_inference_dir = os.path.join(\n",
    "    os.path.dirname(os.getcwd()),\n",
    "    \"models\",\n",
    "    \"models_root\",\n",
    "    \"model_for_inference\",\n",
    "    \"ras_pinn\"\n",
    ")\n",
    "files = sorted(os.listdir(model_inference_dir))\n",
    "print(\"Files in directory:\")\n",
    "for f in files:\n",
    "    print(f\" - {f}\")\n",
    "if len(files) == 0:\n",
    "    raise FileNotFoundError(f\"No files found in {model_inference_dir}\")\n",
    "model_file = files[0]  # first file in directory\n",
    "print(f\"Using model file: {model_file}\")\n",
    "landscape_save_dir = os.path.join(\n",
    "    os.path.dirname(os.getcwd()),\n",
    "    \"notebooks\",\n",
    "    \"loss_landscape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES\n",
    "import copy\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # or ':16:8'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdmolops\n",
    "from rdkit.Chem import rdDistGeom as molDG\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem.rdchem import GetPeriodicTable\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch_geometric.nn import MessagePassing, GCNConv, global_mean_pool, GATConv\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn.inits import reset\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# FUNCTIONS\n",
    "from data_processing import load_dataset, smiles_to_graph, process_dataset, generate_graphs\n",
    "from data_processing_improved import load_dataset_3d, smiles_to_graph_3d, process_dataset_3d\n",
    "from path_helpers import get_path\n",
    "from stats_compute import compute_statistics, scale_graphs\n",
    "from mol_visualize import recon_3d, viz_3d\n",
    "from smart_loader import load_model_for_inference\n",
    "import ModelArchitecture\n",
    "from EnhancedDataSplit import DataSplitter\n",
    "from collections import defaultdict\n",
    "from typing import Tuple, List\n",
    "\n",
    "# DIRECTORY SETUP\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETER SETTINGS\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# Reproducibility settings\n",
    "seed = 21\n",
    "split_seed = 42\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "runtime = timestamp\n",
    "\n",
    "###########################\n",
    "selected_device = 'cuda' # either 'cuda' or 'cpu\n",
    "device = torch.device(selected_device)\n",
    "runtyp = 'model_for_inference'\n",
    "path = os.path.join(model_inference_dir, model_file)\n",
    "model = load_model_for_inference(path, device = device)\n",
    "###########################\n",
    "\n",
    "# CUDA Deterministic (ON/OFF SETTING)\n",
    "# For PyTorch\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "print('device           :', device)\n",
    "print('seed             :', seed)\n",
    "print('split seed       :', split_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARITY PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD & GRAPH GENERATION\n",
    "df_components = load_dataset(get_path(file_name = 'components_set.csv', folder_name='datasets'))\n",
    "smiles_dict = dict(zip(df_components['Abbreviation'], df_components['SMILES']))\n",
    "df_systems = load_dataset(get_path(file_name = 'systems_set.csv', folder_name='datasets'))\n",
    "smiles_list = df_components[\"SMILES\"].dropna().tolist()\n",
    "mol_name_dict = smiles_dict.copy()\n",
    "# GRAPH\n",
    "system_graphs = process_dataset(df_systems, smiles_dict)\n",
    "# LOAD DATASET\n",
    "splitter = DataSplitter(system_graphs, random_state=split_seed)\n",
    "splitter.print_dataset_stats()\n",
    "# Options: unseen_amine_split (completely new amines in test set) or stratified_random_split (train val test uncontaminated)\n",
    "train_data, val_data, test_data = splitter.rarity_aware_unseen_amine_split()\n",
    "#Retrieve the statistics of train_data\n",
    "stats = compute_statistics(train_data)\n",
    "conc_mean = stats[0]\n",
    "conc_std = stats[1]\n",
    "temp_mean = stats[2]\n",
    "temp_std = stats[3]\n",
    "pco2_mean = stats[4]\n",
    "pco2_std = stats[5]\n",
    "#Apply the scaling to validation and test\n",
    "original_train_data = copy.deepcopy(train_data)\n",
    "original_val_data = copy.deepcopy(val_data)\n",
    "original_test_data = copy.deepcopy(test_data)\n",
    "combined_original_data = original_train_data + original_val_data + original_test_data\n",
    "train_data = scale_graphs(train_data, conc_mean, conc_std, temp_mean, temp_std, pco2_mean, pco2_std)\n",
    "val_data = scale_graphs(val_data, conc_mean, conc_std, temp_mean, temp_std, pco2_mean, pco2_std)\n",
    "test_data = scale_graphs(test_data, conc_mean, conc_std, temp_mean, temp_std, pco2_mean, pco2_std)\n",
    "#Load the data into DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=len(train_data), shuffle=False)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARITY PLOT GENERATION\n",
    "def collect_predictions_and_true_values(model, data_loader, device):\n",
    "    predictions = []\n",
    "    true_values = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            predictions.extend(output.cpu().numpy())\n",
    "            true_values.extend(data.aco2.cpu().numpy())\n",
    "    \n",
    "    return predictions, true_values\n",
    "\n",
    "# Function to calculate R² and RMSE\n",
    "def calculate_metrics(true_values, predictions):\n",
    "    r2 = r2_score(true_values, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, predictions))\n",
    "    return r2, rmse\n",
    "\n",
    "# Function to save metrics to CSV\n",
    "def save_metrics_to_csv(r2_train, rmse_train, r2_val, rmse_val, r2_test, rmse_test, parent_directory):\n",
    "    # Create the metrics dictionary\n",
    "    metrics_data = {\n",
    "        'Dataset': ['Training', 'Validation', 'Test'],\n",
    "        'R2': [r2_train, r2_val, r2_test],\n",
    "        'RMSE': [rmse_train, rmse_val, rmse_test]\n",
    "    }\n",
    "\n",
    "# Function to plot the parity plot\n",
    "def plot_parity_plot(train_true_values, train_predictions, val_true_values, val_predictions, test_true_values, test_predictions):\n",
    "    fontsize = 17\n",
    "    matplotlib.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "    # Calculate metrics\n",
    "    r2_train, rmse_train = calculate_metrics(train_true_values, train_predictions)\n",
    "    r2_val, rmse_val = calculate_metrics(val_true_values, val_predictions)\n",
    "    r2_test, rmse_test = calculate_metrics(test_true_values, test_predictions)\n",
    "\n",
    "    # Plot parity plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Training data parity plot\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.scatter(train_true_values, train_predictions, edgecolors='b', alpha=0.5, c = 'b')\n",
    "    plt.plot([-0.1, max(train_true_values)+0.5], [-0.1, max(train_true_values)+0.5], 'k--', linewidth=2)\n",
    "    plt.xlabel('Actual Loading', fontsize=fontsize)\n",
    "    plt.ylabel('Predicted Loading', fontsize=fontsize)\n",
    "    plt.xlim(-0.1, max(train_true_values)+0.5)\n",
    "    plt.ylim(-0.1, max(train_true_values)+0.5)\n",
    "    plt.xticks(fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    plt.title('Training Set Parity Plot', fontsize=fontsize)\n",
    "    plt.text(0.05, 0.95, f'R² = {r2_train:.4f}\\nRMSE = {rmse_train:.4f}', transform=plt.gca().transAxes, fontsize=fontsize, verticalalignment='top')\n",
    "\n",
    "    # Validation data parity plot\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.scatter(val_true_values, val_predictions, edgecolors='g', alpha=0.5, c = 'g')\n",
    "    plt.plot([-0.1, max(train_true_values)+0.5], [-0.1, max(train_true_values)+0.5], 'k--', linewidth=2)\n",
    "    plt.xlabel('Actual Loading', fontsize=fontsize)\n",
    "    plt.ylabel('Predicted Loading', fontsize=fontsize)\n",
    "    plt.xlim(-0.1, max(train_true_values)+0.5)\n",
    "    plt.ylim(-0.1, max(train_true_values)+0.5)\n",
    "    plt.xticks(fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    plt.title('Validation Set Parity Plot', fontsize=fontsize)\n",
    "    plt.text(0.05, 0.95, f'R² = {r2_val:.4f}\\nRMSE = {rmse_val:.4f}', transform=plt.gca().transAxes, fontsize=fontsize, verticalalignment='top')\n",
    "\n",
    "    # Test data parity plot\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.scatter(test_true_values, test_predictions, edgecolors='r', alpha=0.5, c = 'r')\n",
    "    plt.plot([-0.1, max(train_true_values)+0.5], [-0.1, max(train_true_values)+0.5], 'k--', linewidth=2)\n",
    "    plt.xlabel('Actual Loading', fontsize=fontsize)\n",
    "    plt.ylabel('Predicted Loading', fontsize=fontsize)\n",
    "    plt.xlim(-0.1, max(train_true_values)+0.5)\n",
    "    plt.ylim(-0.1, max(train_true_values)+0.5)\n",
    "    plt.xticks(fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    plt.title('Test Set Parity Plot', fontsize=fontsize)\n",
    "    plt.text(0.05, 0.95, f'R² = {r2_test:.4f}\\nRMSE = {rmse_test:.4f}', transform=plt.gca().transAxes, fontsize=fontsize, verticalalignment='top')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save metrics to CSV\n",
    "    save_metrics_to_csv(r2_train, rmse_train, r2_val, rmse_val, r2_test, rmse_test, parent_directory)\n",
    "\n",
    "# Collect predictions and true values for training, validation, and test data\n",
    "train_predictions, train_true_values = collect_predictions_and_true_values(model, train_loader, device)\n",
    "val_predictions, val_true_values = collect_predictions_and_true_values(model, val_loader, device)\n",
    "test_predictions, test_true_values = collect_predictions_and_true_values(model, test_loader, device)\n",
    "\n",
    "# Plot the parity plot\n",
    "plot_parity_plot(train_true_values, train_predictions, val_true_values, val_predictions, test_true_values, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSS LANDSCAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def physics_total_loss(model, data, s1=1.0, s2=1.0, s3=1.0,\n",
    "                       pco2_std=None, pco2_mean=None, \n",
    "                       temp_std=None, temp_mean=None, \n",
    "                       conc_std=None, conc_mean=None):\n",
    "    # Prediction loss (MSE on CO2 loading)\n",
    "    main_criterion = nn.MSELoss()\n",
    "    main_loss = main_criterion(model(data).squeeze(), data.aco2.float().squeeze())\n",
    "    \n",
    "    # Physics penalties\n",
    "    loss_p = ModelArchitecture.grad_pres(model, data, pco2_std, pco2_mean, s1)\n",
    "    loss_t = ModelArchitecture.grad_temp(model, data, temp_std, temp_mean, s2)\n",
    "    loss_c = ModelArchitecture.grad_conc(model, data, conc_std, conc_mean, s3)\n",
    "    \n",
    "    return main_loss + loss_p + loss_t + loss_c\n",
    "\n",
    "def get_random_direction(model, device):\n",
    "    direction = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            direction[name] = torch.randn_like(param, device=device)\n",
    "    return direction\n",
    "\n",
    "def normalize_direction(direction, model):\n",
    "    direction_norm = 0\n",
    "    model_norm = 0\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and name in direction:\n",
    "            direction_norm += torch.norm(direction[name]) ** 2\n",
    "            model_norm += torch.norm(param) ** 2\n",
    "    \n",
    "    direction_norm = torch.sqrt(direction_norm)\n",
    "    model_norm = torch.sqrt(model_norm)\n",
    "    \n",
    "    # Normalize direction to have same magnitude as model parameters\n",
    "    for name in direction:\n",
    "        direction[name] = direction[name] * (model_norm / direction_norm)\n",
    "    \n",
    "    return direction\n",
    "\n",
    "def apply_perturbation(model, direction1, direction2, alpha, beta):\n",
    "    perturbed_model = copy.deepcopy(model)\n",
    "    \n",
    "    for name, param in perturbed_model.named_parameters():\n",
    "        if param.requires_grad and name in direction1 and name in direction2:\n",
    "            param.data = param.data + alpha * direction1[name] + beta * direction2[name]\n",
    "    \n",
    "    return perturbed_model\n",
    "\n",
    "def compute_loss_at_point(model, data_loader, criterion, device, target_attr='aco2', \n",
    "                         use_custom_loss=False, custom_loss_kwargs=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    if use_custom_loss and custom_loss_kwargs is None:\n",
    "        custom_loss_kwargs = {}\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        if use_custom_loss:\n",
    "            # Enable gradients only for custom physics loss\n",
    "            with torch.set_grad_enabled(True):\n",
    "                loss = physics_total_loss(model, batch, **custom_loss_kwargs)\n",
    "        else:\n",
    "            # Standard evaluation - no gradients needed\n",
    "            with torch.no_grad():\n",
    "                output = model(batch)\n",
    "                target = getattr(batch, target_attr)\n",
    "                loss = criterion(output.squeeze(), target.float())\n",
    "        \n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "        total_samples += batch.num_graphs\n",
    "    \n",
    "    return total_loss / total_samples\n",
    "\n",
    "def compute_hessian_trace(model, data_loader, criterion, device, target_attr='aco2', use_custom_loss=False, custom_loss_kwargs=None):\n",
    "    \"\"\"\n",
    "    Approximates the trace of the Hessian matrix by computing the sum of second-order gradients.\n",
    "    Uses Hutchinson's method with Rademacher random vectors if needed.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    trace = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        if use_custom_loss:\n",
    "            loss = physics_total_loss(model, batch, **custom_loss_kwargs)\n",
    "        else:\n",
    "            output = model(batch)\n",
    "            target = getattr(batch, target_attr)\n",
    "            loss = criterion(output.squeeze(), target.float())\n",
    "\n",
    "        grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
    "        for g in grads:\n",
    "            if g is not None and g.requires_grad:\n",
    "                trace += torch.sum(torch.autograd.grad(g, model.parameters(), grad_outputs=torch.ones_like(g), retain_graph=True)[0] ** 2).item()\n",
    "\n",
    "        total_samples += batch.num_graphs\n",
    "        break  # Only compute on 1 batch for speed\n",
    "\n",
    "    return trace\n",
    "\n",
    "# SEPARATED CALCULATION FUNCTION\n",
    "def create_loss_landscape(model, data_loader, criterion, device, \n",
    "                         grid_size=21, perturbation_range=1.0, target_attr='aco2',\n",
    "                         use_custom_loss=False, custom_loss_kwargs=None):\n",
    "    \"\"\"\n",
    "    Compute loss landscape data without visualization.\n",
    "    Returns all necessary data for plotting.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Generating random directions...\")\n",
    "    # Generate two random orthogonal directions\n",
    "    direction1 = get_random_direction(model, device)\n",
    "    direction2 = get_random_direction(model, device)\n",
    "    \n",
    "    # Normalize directions\n",
    "    direction1 = normalize_direction(direction1, model)\n",
    "    direction2 = normalize_direction(direction2, model)\n",
    "    \n",
    "    # Make directions orthogonal (Gram-Schmidt process)\n",
    "    dot_product = 0\n",
    "    for name in direction1:\n",
    "        dot_product += torch.sum(direction1[name] * direction2[name])\n",
    "    \n",
    "    for name in direction2:\n",
    "        direction2[name] = direction2[name] - dot_product * direction1[name]\n",
    "    \n",
    "    direction2 = normalize_direction(direction2, model)\n",
    "    \n",
    "    print(f\"Computing loss landscape on {grid_size}x{grid_size} grid...\")\n",
    "    \n",
    "    # Create coordinate grids\n",
    "    alphas = np.linspace(-perturbation_range, perturbation_range, grid_size)\n",
    "    betas = np.linspace(-perturbation_range, perturbation_range, grid_size)\n",
    "    \n",
    "    # Initialize loss surface\n",
    "    loss_surface = np.zeros((grid_size, grid_size))\n",
    "    \n",
    "    # Compute loss for each point in the grid\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        for j, beta in enumerate(betas):\n",
    "            if (i * grid_size + j) % 50 == 0:\n",
    "                print(f\"Progress: {(i * grid_size + j) / (grid_size * grid_size) * 100:.1f}%\")\n",
    "            \n",
    "            # Create perturbed model\n",
    "            perturbed_model = apply_perturbation(model, direction1, direction2, alpha, beta)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = compute_loss_at_point(\n",
    "                perturbed_model, data_loader, criterion, device, target_attr,\n",
    "                use_custom_loss=use_custom_loss, custom_loss_kwargs=custom_loss_kwargs\n",
    "            )\n",
    "            loss_surface[i, j] = loss\n",
    "    \n",
    "    # Compute Hessian trace\n",
    "    hessian_trace = compute_hessian_trace(model, data_loader, criterion, device, target_attr, use_custom_loss, custom_loss_kwargs)\n",
    "    \n",
    "    print(\"Loss landscape computation complete!\")\n",
    "    print(f\"Hessian Trace (approximate): {hessian_trace:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'alphas': alphas,\n",
    "        'betas': betas, \n",
    "        'loss_surface': loss_surface,\n",
    "        'hessian_trace': hessian_trace,\n",
    "        'grid_size': grid_size,\n",
    "        'perturbation_range': perturbation_range\n",
    "    }\n",
    "\n",
    "# SEPARATED VISUALIZATION FUNCTIONS\n",
    "def plot_loss_landscape_2d(landscape_data, save_path=None, title_suffix=\"\"):\n",
    "    \"\"\"\n",
    "    Create high-quality 2D contour plot from pre-computed landscape data\n",
    "    \"\"\"\n",
    "    alphas = landscape_data['alphas']\n",
    "    betas = landscape_data['betas']\n",
    "    loss_surface = landscape_data['loss_surface']\n",
    "    \n",
    "    fig = go.Figure(data=go.Contour(\n",
    "        z=loss_surface.T,\n",
    "        x=alphas,\n",
    "        y=betas,\n",
    "        colorscale='Turbo',\n",
    "        contours=dict(start=np.min(loss_surface), end=np.max(loss_surface), \n",
    "                      size=(np.max(loss_surface)-np.min(loss_surface))/40),\n",
    "        colorbar=dict(title=\"\", tickformat=\".2f\",len=1.035,\n",
    "                      y=0.5,\n",
    "                      yanchor='middle',\n",
    "                      tickfont=dict(size=30)\n",
    "                      ),\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[0],\n",
    "        y=[0],\n",
    "        mode='markers+text',\n",
    "        marker=dict(color='red', size=20, symbol='star'),\n",
    "        text=[f\"Trained Model<br>{loss_surface[loss_surface.shape[0]//2, loss_surface.shape[1]//2]:.3f}\"],\n",
    "        textposition='top center',\n",
    "        textfont=dict(\n",
    "            color='white',     # change text color here\n",
    "            size=16,           # optional: text size\n",
    "            family='Arial'     # optional: font family\n",
    "        ),\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(tickfont=dict(size=30),\n",
    "                   title=dict(text='Direction 1 (α)', standoff=10,font=dict(size=30))),\n",
    "        yaxis=dict(tickfont=dict(size=30),\n",
    "                   title=dict(text='Direction 2 (β)', standoff=0,font=dict(size=30))),\n",
    "        margin=dict(l=80, r=50, t=100, b=80),\n",
    "        font=dict(size=16, family='Serif'),\n",
    "        width=800,\n",
    "        height=700\n",
    "    )\n",
    "\n",
    "    if save_path:\n",
    "        fig.write_image(f\"{save_path}_2d_plotly.png\", width=900, height=900, scale=10, \n",
    "               engine=\"kaleido\", format=\"png\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def plot_loss_landscape_3d(landscape_data, save_path=None, title_suffix=\"\"):\n",
    "    alphas = landscape_data['alphas']\n",
    "    betas = landscape_data['betas']\n",
    "    loss_surface = landscape_data['loss_surface']\n",
    "    \n",
    "    i0 = np.argmin(np.abs(alphas))  # index of closest to 0\n",
    "    j0 = np.argmin(np.abs(betas))\n",
    "    original_loss = loss_surface[i0, j0]\n",
    "\n",
    "    min_loss = np.min(loss_surface)\n",
    "    max_loss = np.max(loss_surface)\n",
    "\n",
    "    # Generate tick positions and labels\n",
    "    alpha_ticks = np.linspace(alphas[0], alphas[-1], 5)\n",
    "    alpha_ticklabels = [f\"{val:.2f}\" for val in alpha_ticks]\n",
    "    \n",
    "    beta_ticks = np.linspace(betas[0], betas[-1], 5)\n",
    "    beta_ticklabels = [f\"{val:.2f}\" for val in beta_ticks]\n",
    "\n",
    "    num_z_ticks = 5\n",
    "    z_ticks = np.linspace(min_loss, max_loss, num_z_ticks)\n",
    "    z_ticklabels = [f\"{val:.2f}\" for val in z_ticks]\n",
    "\n",
    "    fig = go.Figure(data=[\n",
    "        go.Surface(\n",
    "            z=loss_surface.T,\n",
    "            x=alphas,\n",
    "            y=betas,\n",
    "            colorscale='Turbo',\n",
    "            lighting=dict(\n",
    "                ambient=0.6,   # soft overall light\n",
    "                diffuse=0.1,   # gentle shading\n",
    "                specular=0.2,  # very subtle highlights\n",
    "                roughness=0.6  # matte, not glossy\n",
    "            ),\n",
    "            lightposition=dict(x=30, y=50, z=100),\n",
    "            colorbar=dict(\n",
    "                title='Loss',\n",
    "                title_font=dict(size=14, family='Serif'),\n",
    "                tickfont=dict(size=14, family='Serif'),\n",
    "                thickness=20,\n",
    "                len=0.45,\n",
    "                outlinecolor='black',\n",
    "                outlinewidth=1,\n",
    "                x=0.95,\n",
    "                y=0.52,\n",
    "                tickmode='array',\n",
    "                tickvals=z_ticks,\n",
    "                ticktext=z_ticklabels\n",
    "            ),\n",
    "            showscale=False,\n",
    "            hoverinfo='x+y+z',\n",
    "        ),\n",
    "        go.Scatter3d(\n",
    "            x=[0],\n",
    "            y=[0],\n",
    "            z=[original_loss],\n",
    "            mode='markers',\n",
    "            marker=dict(color='red', size=7, symbol='circle'),\n",
    "            name='Original Model',\n",
    "            hovertemplate='Original Loss: %{z:.3f}<extra></extra>'\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    import math\n",
    "\n",
    "    angle_deg = -30\n",
    "    angle_rad = math.radians(angle_deg)\n",
    "\n",
    "    # Original eye coordinates\n",
    "    x0, y0, z0 = 1.5, 1.3, 1.0\n",
    "    zoom_factor = 1.00\n",
    "    # Rotate clockwise around z-axis\n",
    "    x_new = x0 * math.cos(angle_rad) + y0 * math.sin(angle_rad)\n",
    "    y_new = -x0 * math.sin(angle_rad) + y0 * math.cos(angle_rad)\n",
    "    z_new = z0  # keep height the same\n",
    "    \n",
    "    fig.update_layout(\n",
    "        scene_aspectmode='manual',\n",
    "        scene_aspectratio=dict(x=1, y=1, z=1),\n",
    "        font=dict(size=14, family='Serif', color='black'),\n",
    "        width=800,\n",
    "        height=700,\n",
    "        margin=dict(l=0, r=0, b=0, t=0, pad=0),\n",
    "        scene=dict(\n",
    "            camera=dict(\n",
    "                eye=dict(x=x_new*zoom_factor, y=y_new*zoom_factor, z=z_new*zoom_factor)\n",
    "            ),\n",
    "            xaxis=dict(\n",
    "                title='Direction 1 (α)',\n",
    "                title_font=dict(size=16, family='Serif'),\n",
    "                tickfont=dict(size=14, family='Serif'),\n",
    "                showgrid=False,\n",
    "                gridcolor='black',\n",
    "                zeroline=False,\n",
    "                zerolinecolor='black',\n",
    "                zerolinewidth=2,\n",
    "                tickmode='array',\n",
    "                tickvals=alpha_ticks,\n",
    "                ticktext=alpha_ticklabels,\n",
    "                range=[alphas[0], alphas[-1]],\n",
    "                backgroundcolor='white',\n",
    "                showbackground=True,\n",
    "                linewidth=2,\n",
    "                linecolor='black',\n",
    "                mirror=False,\n",
    "                tickangle=-20,\n",
    "                visible=False\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title='Direction 2 (β)',\n",
    "                title_font=dict(size=16, family='Serif'),\n",
    "                tickfont=dict(size=14, family='Serif'),\n",
    "                showgrid=False,\n",
    "                gridcolor='black',\n",
    "                zeroline=False,\n",
    "                zerolinecolor='black',\n",
    "                zerolinewidth=2,\n",
    "                tickmode='array',\n",
    "                tickvals=beta_ticks,\n",
    "                ticktext=beta_ticklabels,\n",
    "                range=[betas[0], betas[-1]],\n",
    "                backgroundcolor='white',\n",
    "                showbackground=True,\n",
    "                linewidth=2,\n",
    "                linecolor='black',\n",
    "                mirror=False,\n",
    "                visible=False\n",
    "            ),\n",
    "            zaxis=dict(\n",
    "                title='Loss',\n",
    "                title_font=dict(size=16, family='Serif'),\n",
    "                tickfont=dict(size=14, family='Serif'),\n",
    "                showgrid=False,\n",
    "                gridcolor='black',\n",
    "                zeroline=False,\n",
    "                zerolinecolor='black',\n",
    "                tickmode='array',\n",
    "                tickvals=z_ticks,\n",
    "                ticktext=z_ticklabels,\n",
    "                backgroundcolor='white',\n",
    "                showbackground=True,\n",
    "                linewidth=2,\n",
    "                linecolor='black',\n",
    "                mirror=False,\n",
    "                tickangle=-7,\n",
    "                visible=False\n",
    "            ),\n",
    "            bgcolor=\"white\"\n",
    "        ),\n",
    "        legend=dict(\n",
    "            font=dict(size=14, family='Serif'),\n",
    "            bordercolor='black',\n",
    "            borderwidth=1,\n",
    "            yanchor='top',\n",
    "            y=0.95,\n",
    "            xanchor='right',\n",
    "            x=0.95,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if save_path:\n",
    "        fig.write_image(f\"{save_path}_3d_plotly.png\", width=900, height=900, scale=5, \n",
    "               engine=\"kaleido\", format=\"png\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def plot_both_landscapes(landscape_data, save_path=None, title_suffix=\"\"):\n",
    "    \"\"\"\n",
    "    Plot both 2D and 3D visualizations from the same data\n",
    "    \"\"\"\n",
    "    plot_loss_landscape_2d(landscape_data, save_path, title_suffix)\n",
    "    plot_loss_landscape_3d(landscape_data, save_path, title_suffix)\n",
    "\n",
    "# CONVENIENCE FUNCTION (backwards compatibility)\n",
    "def visualize_loss_landscape(model, data_loader, criterion, device, \n",
    "                           grid_size=21, perturbation_range=1.0, save_path=None, \n",
    "                           target_attr='aco2', use_custom_loss=False, custom_loss_kwargs=None):\n",
    "    \"\"\"\n",
    "    Combined function for backwards compatibility - computes and visualizes\n",
    "    \"\"\"\n",
    "    print(\"Starting loss landscape visualization...\")\n",
    "    print(f\"Grid size: {grid_size}x{grid_size}\")\n",
    "    print(f\"Perturbation range: ±{perturbation_range}\")\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    # Compute landscape\n",
    "    landscape_data = create_loss_landscape(\n",
    "        model, data_loader, criterion, device, grid_size, perturbation_range, target_attr,\n",
    "        use_custom_loss=use_custom_loss, custom_loss_kwargs=custom_loss_kwargs\n",
    "    )\n",
    "    \n",
    "    # Visualize\n",
    "    print(\"Creating visualizations...\")\n",
    "    plot_both_landscapes(landscape_data, save_path)\n",
    "    \n",
    "    print(\"Loss landscape visualization complete!\")\n",
    "    \n",
    "    return landscape_data\n",
    "\n",
    "\n",
    "# USAGE EXAMPLES AND INSTRUCTIONS\n",
    "print(\"Loss landscape visualization functions loaded!\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SEPARATED CALCULATION & VISUALIZATION WORKFLOW:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1. COMPUTE LANDSCAPE DATA (once):\")\n",
    "print(\"   landscape_data = create_loss_landscape(model, data_loader, nn.MSELoss(), device, grid_size=15)\")\n",
    "print(\"\\n2. VISUALIZE MULTIPLE TIMES (fast):\")\n",
    "print(\"   plot_loss_landscape_2d(landscape_data)  # 2D contour\")\n",
    "print(\"   plot_loss_landscape_3d(landscape_data)  # 3D surface\") \n",
    "print(\"   plot_both_landscapes(landscape_data)    # Both plots\")\n",
    "print(\"\\n3. SAVE/LOAD LANDSCAPE DATA:\")\n",
    "print(\"   # Save: np.savez('landscape.npz', **landscape_data)\")\n",
    "print(\"   # Load: landscape_data = dict(np.load('landscape.npz'))\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # ONE-TIME LANDSCAPE GENERATION\n",
    "custom_loss_kwargs = {\n",
    "    's1': 10,          # Strength of pCO2 gradient penalty\n",
    "    's2': 1000,          # Strength of temp gradient penalty\n",
    "    's3': 10,          # Strength of conc gradient penalty\n",
    "    'pco2_std': pco2_std, \n",
    "    'pco2_mean': pco2_mean,\n",
    "    'temp_std': temp_std,\n",
    "    'temp_mean': temp_mean,\n",
    "    'conc_std': conc_std,\n",
    "    'conc_mean': conc_mean\n",
    "}\n",
    "\n",
    "# Generate surface data \n",
    "landscape_data = create_loss_landscape(model, train_loader, nn.MSELoss(), device, \n",
    "                                       grid_size=251, \n",
    "                                       perturbation_range=1,\n",
    "                                       use_custom_loss=True, custom_loss_kwargs=custom_loss_kwargs)\n",
    "def save_landscape_npz(landscape_data, filepath):\n",
    "    np.savez_compressed(filepath, **landscape_data)\n",
    "# Save the landscape data\n",
    "save_landscape_npz(landscape_data=landscape_data, filepath=f'{landscape_save_dir}/pinn_best_True_v2.npz') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_landscape_npz(filepath):\n",
    "    loaded = np.load(filepath)\n",
    "    landscape_data = dict(loaded)\n",
    "    loaded.close()\n",
    "    return landscape_data\n",
    "landscape_data = load_landscape_npz(f'{landscape_save_dir}/pinn_best_True_v2.npz')\n",
    "image_save_path = os.path.join(\n",
    "    os.path.dirname(os.getcwd()),\n",
    "    \"notebooks\",\n",
    "    \"loss_landscape\",\n",
    "    \"physMSE_PIGNN\"\n",
    ")\n",
    "\n",
    "plot_both_landscapes(landscape_data, image_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
