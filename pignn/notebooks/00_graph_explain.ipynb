{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # or ':16:8'\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "# FUNCTIONS\n",
    "from data_processing import load_dataset, smiles_to_graph, process_dataset\n",
    "from path_helpers import get_path\n",
    "from stats_compute import compute_statistics, scale_graphs\n",
    "from smart_loader import load_model_for_inference\n",
    "from EnhancedDataSplit import DataSplitter\n",
    "# DIRECTORY SETUP\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETER SETTINGS\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# Reproducibility settings\n",
    "seed = 21\n",
    "split_seed = 42\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "runtime = timestamp\n",
    "\n",
    "###########################\n",
    "model_inference_dir = os.path.join(\n",
    "    os.path.dirname(os.getcwd()),\n",
    "    \"models\",\n",
    "    \"models_root\",\n",
    "    \"model_for_inference\",\n",
    "    \"ras_pinn\"\n",
    ")\n",
    "# List files and pick the first one\n",
    "files = sorted(os.listdir(model_inference_dir))  # sorted to make it deterministic\n",
    "if len(files) == 0:\n",
    "    raise FileNotFoundError(f\"No files found in {model_inference_dir}\")\n",
    "model_file = files[0]  # first file in directory\n",
    "print(f\"Using model file: {model_file}\")\n",
    "# Full path\n",
    "path = os.path.join(model_inference_dir, model_file)\n",
    "########### IMPORTING MODEL ###############\n",
    "selected_device = 'cuda'\n",
    "device = torch.device(selected_device)\n",
    "model = load_model_for_inference(path, device=device)\n",
    "############################################\n",
    "###########################\n",
    "\n",
    "# CUDA Deterministic (ON/OFF SETTING)\n",
    "# For PyTorch\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "print('device           :', device)\n",
    "print('seed             :', seed)\n",
    "print('split seed       :', split_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD & GRAPH GENERATION FOR EITHER SRS OR RAS\n",
    "df_components = load_dataset(get_path(file_name = 'components_set.csv', folder_name='datasets'))\n",
    "smiles_dict = dict(zip(df_components['Abbreviation'], df_components['SMILES']))\n",
    "df_systems = load_dataset(get_path(file_name = 'systems_set.csv', folder_name='datasets'))\n",
    "smiles_list = df_components[\"SMILES\"].dropna().tolist()\n",
    "mol_name_dict = smiles_dict.copy()\n",
    "# GRAPH\n",
    "system_graphs = process_dataset(df_systems, smiles_dict)\n",
    "# LOAD DATASET\n",
    "splitter = DataSplitter(system_graphs, random_state=split_seed)\n",
    "splitter.print_dataset_stats()\n",
    "# Options: rarity_aware_unseen_amine_split stratified_random_split\n",
    "train_data, val_data, test_data = splitter.rarity_aware_unseen_amine_split()\n",
    "#Retrieve the statistics of train_data\n",
    "stats = compute_statistics(train_data)\n",
    "conc_mean = stats[0]\n",
    "conc_std = stats[1]\n",
    "temp_mean = stats[2]\n",
    "temp_std = stats[3]\n",
    "pco2_mean = stats[4]\n",
    "pco2_std = stats[5]\n",
    "#Apply the scaling to validation and test\n",
    "original_train_data = copy.deepcopy(train_data)\n",
    "original_val_data = copy.deepcopy(val_data)\n",
    "original_test_data = copy.deepcopy(test_data)\n",
    "combined_original_data = original_train_data + original_val_data + original_test_data\n",
    "train_data = scale_graphs(train_data, conc_mean, conc_std, temp_mean, temp_std, pco2_mean, pco2_std)\n",
    "val_data = scale_graphs(val_data, conc_mean, conc_std, temp_mean, temp_std, pco2_mean, pco2_std)\n",
    "test_data = scale_graphs(test_data, conc_mean, conc_std, temp_mean, temp_std, pco2_mean, pco2_std)\n",
    "#Load the data into DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mol name processing\n",
    "test_molecules = list(set([data.name for data in test_data]))\n",
    "# Separate by molecule name\n",
    "molecule_groups_test = {}\n",
    "for mol_name in test_molecules:\n",
    "   molecule_groups_test[mol_name] = [data for data in test_data if data.name == mol_name]\n",
    "\n",
    "val_molecules = list(set([data.name for data in val_data]))\n",
    "\n",
    "# Separate by molecule name\n",
    "molecule_groups_val = {}\n",
    "for mol_name in val_molecules:\n",
    "   molecule_groups_val[mol_name] = [data for data in val_data if data.name == mol_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL WRAPPER\n",
    "class EmbeddingsExtractor(torch.nn.Module):\n",
    "    def __init__(self, full_model):\n",
    "        super().__init__()\n",
    "        self.graph_block = full_model.graph_block\n",
    "        self.use_adaptive_pooling = full_model.use_adaptive_pooling\n",
    "        if self.use_adaptive_pooling:\n",
    "            self.adaptive_pool = full_model.adaptive_pool\n",
    "\n",
    "    def forward(self, data, extract_embeddings=False, include_conditions=False):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        x = self.graph_block(x, edge_index, edge_attr)\n",
    "        \n",
    "        if self.use_adaptive_pooling:\n",
    "            x = self.adaptive_pool(x, batch)\n",
    "        else:\n",
    "            x = global_mean_pool(x, batch)\n",
    "\n",
    "        if extract_embeddings:\n",
    "            return x\n",
    "\n",
    "        if include_conditions:\n",
    "            additional_features = torch.stack([data.conc, data.temp, data.pco2], dim=1).float()\n",
    "            x = torch.cat([x, additional_features], dim=1)\n",
    "        return x\n",
    "\n",
    "class FCNNWrapper:\n",
    "    def __init__(self, fc_block, device):\n",
    "        self.fc_block = fc_block\n",
    "        self.device = device\n",
    "        self.fc_block.eval()\n",
    "    def __call__(self, x_numpy):\n",
    "        x_tensor = torch.from_numpy(x_numpy).float().to(self.device)\n",
    "        with torch.no_grad():\n",
    "            y = self.fc_block(x_tensor)\n",
    "        return y.cpu().numpy()\n",
    "fc_wrapper = FCNNWrapper(model.fc_block, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter molecular graph from combined dataset  & define embedding_generator\n",
    "unique_named_graphs = {}\n",
    "for graph in combined_original_data:\n",
    "    name = graph['name']\n",
    "    if name not in unique_named_graphs:\n",
    "        unique_named_graphs[name] = graph\n",
    "unique_graph_list = list(unique_named_graphs.values())\n",
    "mol_loader = DataLoader(unique_graph_list, batch_size=batch_size, shuffle=False)\n",
    "# Execute the EmbeddingsExtractor\n",
    "embedding_generator = EmbeddingsExtractor(model).to(device)\n",
    "embedding_generator.eval()\n",
    "all_embeddings = []\n",
    "all_amines = []\n",
    "all_data = []\n",
    "with torch.no_grad():\n",
    "    for data in mol_loader:\n",
    "        data = data.to(device)\n",
    "        combined_embedding = embedding_generator(data, \n",
    "                                                 include_conditions=False, \n",
    "                                                 extract_embeddings=True)\n",
    "        all_embeddings.append(combined_embedding.cpu())\n",
    "        all_amines.extend(data.name)\n",
    "        all_data.extend(data.cpu().to_data_list())\n",
    "\n",
    "# Now after the loop\n",
    "all_embeddings = torch.cat(all_embeddings)\n",
    "index_to_name = {i: name for i, name in enumerate(all_amines)}\n",
    "\n",
    "# Assigning extracted embeddings to Data object as tensor\n",
    "name_to_embedding = {name: emb for name, emb in zip(all_amines, all_embeddings)}\n",
    "for dataset in [train_data, val_data, test_data]:\n",
    "    for data in dataset:\n",
    "        name = data.name\n",
    "        data.embedding = name_to_embedding[name]\n",
    "        if name in smiles_dict:\n",
    "            data.smiles = smiles_dict[name]\n",
    "        else:\n",
    "            data.smiles = None\n",
    "\n",
    "def extract_combined_vectors(loader, model, embedding_generator, device):\n",
    "    vectors = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            graph_emb = embedding_generator(data, extract_embeddings=True)\n",
    "            ext_feats = torch.stack([data.conc, data.temp, data.pco2], dim=1).float()\n",
    "            combined = torch.cat([graph_emb, ext_feats], dim=1)\n",
    "            vectors.append(combined.cpu())\n",
    "    return torch.cat(vectors).numpy()\n",
    "background_vectors = extract_combined_vectors(train_loader, model, embedding_generator, device)\n",
    "val_vectors        = extract_combined_vectors(val_loader, model, embedding_generator, device)\n",
    "test_vectors       = extract_combined_vectors(test_loader, model, embedding_generator, device)\n",
    "num_emb_dims = test_vectors.shape[1] - 3\n",
    "feature_names = [f\"embedding_{i}\" for i in range(num_emb_dims)] + ['conc', 'temp', 'pco2']\n",
    "\n",
    "combined_data_with_embeddings = train_data + val_data + test_data\n",
    "unique_named_graphs_with_embeddings = {}\n",
    "for graph in combined_data_with_embeddings:\n",
    "    name = graph['name']\n",
    "    if name not in unique_named_graphs_with_embeddings:\n",
    "        unique_named_graphs_with_embeddings[name] = graph\n",
    "unique_graph_list_with_embeddings = list(unique_named_graphs_with_embeddings.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from collections import defaultdict\n",
    "import numpy as np\n",
    "import warnings\n",
    "import shap\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*NumPy global RNG.*\")\n",
    "\n",
    "# ---- 1) Prepare background once ----\n",
    "background = np.stack([\n",
    "    np.concatenate([data.embedding.numpy(), \n",
    "                    np.array([data.conc, data.temp, data.pco2])])\n",
    "    for data in train_data\n",
    "])\n",
    "background = background[np.random.choice(background.shape[0], 100, replace=False)]\n",
    "\n",
    "explainer = shap.KernelExplainer(fc_wrapper, background)\n",
    "\n",
    "# ---- 2) Prepare full test set ----\n",
    "test_vectors = np.stack([\n",
    "    np.concatenate([data.embedding.numpy(), \n",
    "                    np.array([data.conc, data.temp, data.pco2])])\n",
    "    for data in val_data\n",
    "])\n",
    "molecule_names = [data.name for data in val_data]\n",
    "\n",
    "# ---- 3) Compute SHAP for full test set ----\n",
    "shap_values = explainer.shap_values(test_vectors)\n",
    "\n",
    "# ---- 4) Plot summary for all test samples ----\n",
    "shap.summary_plot(\n",
    "    np.squeeze(shap_values),\n",
    "    test_vectors,\n",
    "    feature_names=feature_names,\n",
    "    plot_type=\"dot\",\n",
    "    show=True,\n",
    "    max_display=10\n",
    ")\n",
    "\n",
    "# ---- 5) Extract top 5 embeddings per molecule ----\n",
    "embedding_size = len(train_data[0].embedding.numpy())\n",
    "molecule_top_embeddings = defaultdict(dict)\n",
    "\n",
    "for molecule_name in set(molecule_names):\n",
    "    indices_mask = [i for i, name in enumerate(molecule_names) if name == molecule_name]\n",
    "    molecule_vectors = test_vectors[indices_mask]\n",
    "    molecule_shap = np.abs(np.squeeze(shap_values)[indices_mask, :embedding_size]).mean(axis=0)\n",
    "    top5_indices = np.argsort(molecule_shap)[-5:][::-1]\n",
    "    avg_embeddings = molecule_vectors[:, :embedding_size].mean(axis=0)\n",
    "    top5_embeddings = avg_embeddings[top5_indices]\n",
    "    \n",
    "    molecule_top_embeddings[molecule_name] = {\n",
    "        'indices': top5_indices,\n",
    "        'values': top5_embeddings,\n",
    "        'importance_scores': molecule_shap[top5_indices]\n",
    "    }\n",
    "\n",
    "    print(f\"\\n=== {molecule_name} ===\")\n",
    "    print(f\"Top 5 embedding indices: {top5_indices}\")\n",
    "    print(f\"Top 5 embedding values: {top5_embeddings}\")\n",
    "    print(f\"Importance scores: {molecule_shap[top5_indices]}\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "SMILES -> CC(CN(C)C)O \n",
      " Conc: 2 M \n",
      " Temp: 313.15 K \n",
      " pCO2: 15 kPa \n",
      " α Pred -> 0.64809 mol/mol\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "SMILES -> CC(CN(C)C)O \n",
      " Conc: 2 M \n",
      " Temp: 313.15 K \n",
      " pCO2: 15 kPa \n",
      " α Pred -> 0.64809 mol/mol\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hypothesis generator\n",
    "from torch_geometric.data import Batch\n",
    "import torch\n",
    "\n",
    "def predict_from_smiles(model, smiles_list, conc_list, temp_list, pco2_list,\n",
    "                        conc_mean, conc_std, temp_mean, temp_std, pco2_mean, pco2_std,\n",
    "                        device='cuda'):\n",
    "    \"\"\"\n",
    "    Predict alpha_CO2 from raw SMILES + concentration/temp/pco2,\n",
    "    using scaling from training set. Supports CUDA.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    data_list = []\n",
    "\n",
    "    for smi, conc, temp, pco2 in zip(smiles_list, conc_list, temp_list, pco2_list):\n",
    "        # Convert SMILES → PyG Data\n",
    "        data = smiles_to_graph(smi, None)\n",
    "\n",
    "        # Apply scaling\n",
    "        conc_scaled = (conc - conc_mean) / conc_std\n",
    "        temp_scaled = (temp - temp_mean) / temp_std\n",
    "        pco2_scaled = (pco2 - pco2_mean) / pco2_std\n",
    "\n",
    "        # Attach features as tensors on the same device\n",
    "        data.conc = torch.tensor(conc_scaled, dtype=torch.float, device=device)\n",
    "        data.temp = torch.tensor(temp_scaled, dtype=torch.float, device=device)\n",
    "        data.pco2 = torch.tensor(pco2_scaled, dtype=torch.float, device=device)\n",
    "\n",
    "        data_list.append(data)\n",
    "\n",
    "    # Batch all molecules and move to device\n",
    "    batch_data = Batch.from_data_list(data_list).to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        preds = model(batch_data).squeeze()\n",
    "\n",
    "    return preds.cpu().numpy()\n",
    "def round_significant(x, sig=3):\n",
    "    \"\"\"\n",
    "    Round array or number x to `sig` significant digits\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    return np.array([float(f\"{v:.{sig}g}\") for v in x])\n",
    "\n",
    "# Prediction maker\n",
    "smiles_list = [\"CC(CN(C)C)O\", \"CC(CN(C)C)O\"]\n",
    "conc = 2\n",
    "temp = 313.15\n",
    "pco2 = 15\n",
    "\n",
    "# Repeat the scalars for each SMILES\n",
    "conc_list = [conc] * len(smiles_list)\n",
    "temp_list = [temp] * len(smiles_list)\n",
    "pco2_list = [pco2] * len(smiles_list)\n",
    "\n",
    "preds = round_significant(\n",
    "    predict_from_smiles(\n",
    "        model, smiles_list, conc_list, temp_list, pco2_list,\n",
    "        conc_mean, conc_std, temp_mean, temp_std, pco2_mean, pco2_std,\n",
    "        device='cuda'\n",
    "    ),\n",
    "    sig=5\n",
    ")\n",
    "for smi, pred in zip(smiles_list, preds):\n",
    "    print(40 * '-')\n",
    "    print(f\"SMILES -> {smi} \\n Conc: {conc} M \\n Temp: {temp} K \\n pCO2: {pco2} kPa \\n α Pred -> {pred} mol/mol\")\n",
    "    print(40 * '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTEGRATED GRADIENT ATTRIBUTION (ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_named_graphs = {}\n",
    "for graph in combined_original_data:\n",
    "    name = graph['name']\n",
    "    if name not in unique_named_graphs:\n",
    "        unique_named_graphs[name] = graph\n",
    "unique_graph_list = list(unique_named_graphs.values())\n",
    "mol_loader = DataLoader(unique_graph_list, batch_size=batch_size, shuffle=False)\n",
    "# Execute the EmbeddingsExtractor\n",
    "embedding_generator = EmbeddingsExtractor(model).to(device)\n",
    "embedding_generator.eval()\n",
    "all_embeddings = []\n",
    "all_amines = []\n",
    "all_data = []\n",
    "with torch.no_grad():\n",
    "    for data in mol_loader:\n",
    "        data = data.to(device)\n",
    "        combined_embedding = embedding_generator(data, \n",
    "                                                 include_conditions=False, \n",
    "                                                 extract_embeddings=True)\n",
    "        all_embeddings.append(combined_embedding.cpu())\n",
    "        all_amines.extend(data.name)\n",
    "        all_data.extend(data.cpu().to_data_list())\n",
    "\n",
    "# Now after the loop\n",
    "all_embeddings = torch.cat(all_embeddings)\n",
    "index_to_name = {i: name for i, name in enumerate(all_amines)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "import torch\n",
    "import numpy as np\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from matplotlib import cm, colors\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Modified forward: return pooled embedding vector (all dims)\n",
    "def embedding_forward_all(x, data):\n",
    "    x = embedding_generator.graph_block(x, data.edge_index, data.edge_attr)\n",
    "    return x  # no indexing — return full embedding\n",
    "\n",
    "molecule_node_attributions = {}\n",
    "\n",
    "for molecule_name in [d.name for d in all_data]:\n",
    "    print(f\"\\n=== Captum Analysis for {molecule_name} (ALL embeddings) ===\")\n",
    "    \n",
    "    graph_data = next(data for data in all_data if data.name == molecule_name)\n",
    "    graph_data = graph_data.to(device)\n",
    "    \n",
    "    x = graph_data.x.clone().detach().float().to(device)\n",
    "    x.requires_grad = True\n",
    "    baseline = torch.zeros_like(x)\n",
    "    \n",
    "    ig = IntegratedGradients(lambda x, data: embedding_forward_all(x, data).sum(dim=1))  \n",
    "    # sum over embedding dims → scalar output\n",
    "    \n",
    "    attr = ig.attribute(\n",
    "        inputs=x,\n",
    "        baselines=baseline,\n",
    "        additional_forward_args=(graph_data,),\n",
    "        n_steps=50\n",
    "    )  # shape: (num_nodes, num_node_features)\n",
    "    \n",
    "    # Aggregate feature-level attributions per node → scalar signed attribution\n",
    "    node_signed = attr.sum(dim=1).detach().cpu().numpy()\n",
    "    node_magnitude = np.abs(node_signed)\n",
    "    \n",
    "    molecule_node_attributions[molecule_name] = {\n",
    "        'signed': node_signed,\n",
    "        'magnitude': node_magnitude\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.Chem import AllChem\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops\n",
    "import io\n",
    "\n",
    "def trim_white(img):\n",
    "    \"\"\"Crop extra white space around the molecule drawing.\"\"\"\n",
    "    bg = Image.new(img.mode, img.size, (255, 255, 255))\n",
    "    diff = ImageChops.difference(img, bg)\n",
    "    bbox = diff.getbbox()\n",
    "    if bbox:\n",
    "        return img.crop(bbox)\n",
    "    return img\n",
    "\n",
    "# === Modified IG Visualization ===\n",
    "def visualize_combined_molecule(molecule_data, node_attributions, figsize=(800, 800), save_path=None, show=True):\n",
    "    mol = molecule_data.mol\n",
    "    if mol is None:\n",
    "        print(f\"No RDKit molecule available for {molecule_data.name}\")\n",
    "        return\n",
    "    \n",
    "    mol = Chem.Mol(mol)\n",
    "    if mol.GetNumConformers() == 0:\n",
    "        AllChem.Compute2DCoords(mol)\n",
    "    \n",
    "    node_attribute = node_attributions['signed']\n",
    "    # Normalize the IG results to [-1, 1] range after computation\n",
    "    max_abs_val = max(abs(node_attribute.min()), abs(node_attribute.max()))\n",
    "    if max_abs_val > 0:\n",
    "        node_attribute = node_attribute / max_abs_val  # Scale to [-1, 1]\n",
    "    norm = colors.Normalize(vmin=-1, vmax=1)\n",
    "    cmap = plt.colormaps.get_cmap(\"bwr\")  # blue = negative, red = positive\n",
    "    \n",
    "    # Atom colors\n",
    "    atom_colors = {i: cmap(norm(val))[:3] for i, val in enumerate(node_attribute)}\n",
    "    \n",
    "    # Bond colors: average of connected atoms\n",
    "    bond_colors = {}\n",
    "    for bond in mol.GetBonds():\n",
    "        idx1, idx2 = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        avg_val = (node_attribute[idx1] + node_attribute[idx2]) / 2\n",
    "        bond_colors[bond.GetIdx()] = cmap(norm(avg_val))[:3]\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    # Draw molecule with highlights on top\n",
    "    drawer = rdMolDraw2D.MolDraw2DCairo(figsize[0], figsize[1])\n",
    "    opts = drawer.drawOptions()\n",
    "    opts.useBWAtomPalette()\n",
    "    opts.bondLineWidth = 1.5\n",
    "    opts.atomLabelFontSize = 16\n",
    "    opts.highlightColour = (1.0, 1.0, 1.0)  # Make highlights more transparent\n",
    "    opts.fillHighlights = True\n",
    "    opts.highlightsAreCircles = False\n",
    "    \n",
    "    drawer.DrawMolecule(\n",
    "        mol,\n",
    "        highlightAtoms=list(atom_colors.keys()), \n",
    "        highlightAtomColors=atom_colors,\n",
    "        highlightBonds=list(bond_colors.keys()), \n",
    "        highlightBondColors=bond_colors\n",
    "    )\n",
    "    drawer.FinishDrawing()\n",
    "    \n",
    "    png = drawer.GetDrawingText()\n",
    "    image = Image.open(io.BytesIO(png)).convert(\"RGB\")\n",
    "    image = trim_white(image)\n",
    "    \n",
    "    if save_path:\n",
    "        Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if show:\n",
    "        fig, ax = plt.subplots(figsize=(6, 6), dpi=150)\n",
    "        im = ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"{molecule_data.name} — Type: {molecule_data.type}\", pad=25)\n",
    "        \n",
    "        # Add colorbar\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        cbar = plt.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('Signed Attribution', fontsize=12)\n",
    "        # Set major ticks with interval of 0.5\n",
    "        from matplotlib.ticker import MultipleLocator\n",
    "        cbar.ax.xaxis.set_major_locator(MultipleLocator(0.5))\n",
    "        if save_path:\n",
    "            plt.savefig(f\"{save_path}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    return image\n",
    "\n",
    "# === Run visualization ===\n",
    "for molecule_name in molecule_node_attributions:\n",
    "    mol_data = next(d for d in all_data if d.name == molecule_name)\n",
    "    mol_type = mol_data.type\n",
    "    save_path = f\"IntegratedGradients_fig/all/{molecule_name}_{mol_type}\"\n",
    "    \n",
    "    visualize_combined_molecule(\n",
    "        mol_data, \n",
    "        molecule_node_attributions[molecule_name], \n",
    "        save_path=save_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTEGRATED GRADIENT ATTRIBUTION (TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_named_graphs = {}\n",
    "for graph in original_train_data:\n",
    "    name = graph['name']\n",
    "    if name not in unique_named_graphs:\n",
    "        unique_named_graphs[name] = graph\n",
    "unique_graph_list = list(unique_named_graphs.values())\n",
    "mol_loader = DataLoader(unique_graph_list, batch_size=batch_size, shuffle=False)\n",
    "# Execute the EmbeddingsExtractor\n",
    "embedding_generator = EmbeddingsExtractor(model).to(device)\n",
    "embedding_generator.eval()\n",
    "all_embeddings = []\n",
    "all_amines = []\n",
    "all_data = []\n",
    "with torch.no_grad():\n",
    "    for data in mol_loader:\n",
    "        data = data.to(device)\n",
    "        combined_embedding = embedding_generator(data, \n",
    "                                                 include_conditions=False, \n",
    "                                                 extract_embeddings=True)\n",
    "        all_embeddings.append(combined_embedding.cpu())\n",
    "        all_amines.extend(data.name)\n",
    "        all_data.extend(data.cpu().to_data_list())\n",
    "\n",
    "# Now after the loop\n",
    "all_embeddings = torch.cat(all_embeddings)\n",
    "index_to_name = {i: name for i, name in enumerate(all_amines)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "import torch\n",
    "import numpy as np\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from matplotlib import cm, colors\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Modified forward: return pooled embedding vector (all dims)\n",
    "def embedding_forward_all(x, data):\n",
    "    x = embedding_generator.graph_block(x, data.edge_index, data.edge_attr)\n",
    "    return x  # no indexing — return full embedding\n",
    "\n",
    "molecule_node_attributions = {}\n",
    "\n",
    "for molecule_name in [d.name for d in all_data]:\n",
    "    print(f\"\\n=== Captum Analysis for {molecule_name} (ALL embeddings) ===\")\n",
    "    \n",
    "    graph_data = next(data for data in all_data if data.name == molecule_name)\n",
    "    graph_data = graph_data.to(device)\n",
    "    \n",
    "    x = graph_data.x.clone().detach().float().to(device)\n",
    "    x.requires_grad = True\n",
    "    baseline = torch.zeros_like(x)\n",
    "    \n",
    "    ig = IntegratedGradients(lambda x, data: embedding_forward_all(x, data).sum(dim=1))  \n",
    "    # sum over embedding dims → scalar output\n",
    "    \n",
    "    attr = ig.attribute(\n",
    "        inputs=x,\n",
    "        baselines=baseline,\n",
    "        additional_forward_args=(graph_data,),\n",
    "        n_steps=50\n",
    "    )  # shape: (num_nodes, num_node_features)\n",
    "    \n",
    "    # Aggregate feature-level attributions per node → scalar signed attribution\n",
    "    node_signed = attr.sum(dim=1).detach().cpu().numpy()\n",
    "    node_magnitude = np.abs(node_signed)\n",
    "    \n",
    "    molecule_node_attributions[molecule_name] = {\n",
    "        'signed': node_signed,\n",
    "        'magnitude': node_magnitude\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.Chem import AllChem\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops\n",
    "import io\n",
    "\n",
    "def trim_white(img):\n",
    "    \"\"\"Crop extra white space around the molecule drawing.\"\"\"\n",
    "    bg = Image.new(img.mode, img.size, (255, 255, 255))\n",
    "    diff = ImageChops.difference(img, bg)\n",
    "    bbox = diff.getbbox()\n",
    "    if bbox:\n",
    "        return img.crop(bbox)\n",
    "    return img\n",
    "\n",
    "# === Modified IG Visualization ===\n",
    "def visualize_combined_molecule(molecule_data, node_attributions, figsize=(800, 800), save_path=None, show=True):\n",
    "    mol = molecule_data.mol\n",
    "    if mol is None:\n",
    "        print(f\"No RDKit molecule available for {molecule_data.name}\")\n",
    "        return\n",
    "    \n",
    "    mol = Chem.Mol(mol)\n",
    "    if mol.GetNumConformers() == 0:\n",
    "        AllChem.Compute2DCoords(mol)\n",
    "    \n",
    "    node_attribute = node_attributions['signed']\n",
    "    # Normalize the IG results to [-1, 1] range after computation\n",
    "    max_abs_val = max(abs(node_attribute.min()), abs(node_attribute.max()))\n",
    "    if max_abs_val > 0:\n",
    "        node_attribute = node_attribute / max_abs_val  # Scale to [-1, 1]\n",
    "    norm = colors.Normalize(vmin=-1, vmax=1)\n",
    "    cmap = plt.colormaps.get_cmap(\"bwr\")  # blue = negative, red = positive\n",
    "    \n",
    "    # Atom colors\n",
    "    atom_colors = {i: cmap(norm(val))[:3] for i, val in enumerate(node_attribute)}\n",
    "    \n",
    "    # Bond colors: average of connected atoms\n",
    "    bond_colors = {}\n",
    "    for bond in mol.GetBonds():\n",
    "        idx1, idx2 = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        avg_val = (node_attribute[idx1] + node_attribute[idx2]) / 2\n",
    "        bond_colors[bond.GetIdx()] = cmap(norm(avg_val))[:3]\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    # Draw molecule with highlights on top\n",
    "    drawer = rdMolDraw2D.MolDraw2DCairo(figsize[0], figsize[1])\n",
    "    opts = drawer.drawOptions()\n",
    "    opts.useBWAtomPalette()\n",
    "    opts.bondLineWidth = 1.5\n",
    "    opts.atomLabelFontSize = 16\n",
    "    opts.highlightColour = (1.0, 1.0, 1.0)  # Make highlights more transparent\n",
    "    opts.fillHighlights = True\n",
    "    opts.highlightsAreCircles = False\n",
    "    \n",
    "    drawer.DrawMolecule(\n",
    "        mol,\n",
    "        highlightAtoms=list(atom_colors.keys()), \n",
    "        highlightAtomColors=atom_colors,\n",
    "        highlightBonds=list(bond_colors.keys()), \n",
    "        highlightBondColors=bond_colors\n",
    "    )\n",
    "    drawer.FinishDrawing()\n",
    "    \n",
    "    png = drawer.GetDrawingText()\n",
    "    image = Image.open(io.BytesIO(png)).convert(\"RGB\")\n",
    "    image = trim_white(image)\n",
    "    \n",
    "    if save_path:\n",
    "        Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if show:\n",
    "        fig, ax = plt.subplots(figsize=(6, 6), dpi=150)\n",
    "        im = ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"{molecule_data.name} — Type: {molecule_data.type}\", pad=25)\n",
    "        \n",
    "        # Add colorbar\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        cbar = plt.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('Signed Attribution', fontsize=12)\n",
    "        # Set major ticks with interval of 0.5\n",
    "        from matplotlib.ticker import MultipleLocator\n",
    "        cbar.ax.xaxis.set_major_locator(MultipleLocator(0.5))\n",
    "        if save_path:\n",
    "            plt.savefig(f\"{save_path}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    return image\n",
    "\n",
    "# === Run visualization ===\n",
    "for molecule_name in molecule_node_attributions:\n",
    "    mol_data = next(d for d in all_data if d.name == molecule_name)\n",
    "    mol_type = mol_data.type\n",
    "    save_path = f\"IntegratedGradients_fig/train/{molecule_name}_{mol_type}\"\n",
    "    \n",
    "    visualize_combined_molecule(\n",
    "        mol_data, \n",
    "        molecule_node_attributions[molecule_name], \n",
    "        save_path=save_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTEGRATED GRADIENT ATTRIBUTION (VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_named_graphs = {}\n",
    "for graph in original_val_data:\n",
    "    name = graph['name']\n",
    "    if name not in unique_named_graphs:\n",
    "        unique_named_graphs[name] = graph\n",
    "unique_graph_list = list(unique_named_graphs.values())\n",
    "mol_loader = DataLoader(unique_graph_list, batch_size=batch_size, shuffle=False)\n",
    "# Execute the EmbeddingsExtractor\n",
    "embedding_generator = EmbeddingsExtractor(model).to(device)\n",
    "embedding_generator.eval()\n",
    "all_embeddings = []\n",
    "all_amines = []\n",
    "all_data = []\n",
    "with torch.no_grad():\n",
    "    for data in mol_loader:\n",
    "        data = data.to(device)\n",
    "        combined_embedding = embedding_generator(data, \n",
    "                                                 include_conditions=False, \n",
    "                                                 extract_embeddings=True)\n",
    "        all_embeddings.append(combined_embedding.cpu())\n",
    "        all_amines.extend(data.name)\n",
    "        all_data.extend(data.cpu().to_data_list())\n",
    "\n",
    "# Now after the loop\n",
    "all_embeddings = torch.cat(all_embeddings)\n",
    "index_to_name = {i: name for i, name in enumerate(all_amines)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "import torch\n",
    "import numpy as np\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from matplotlib import cm, colors\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Modified forward: return pooled embedding vector (all dims)\n",
    "def embedding_forward_all(x, data):\n",
    "    x = embedding_generator.graph_block(x, data.edge_index, data.edge_attr)\n",
    "    return x  # no indexing — return full embedding\n",
    "\n",
    "molecule_node_attributions = {}\n",
    "\n",
    "for molecule_name in [d.name for d in all_data]:\n",
    "    print(f\"\\n=== Captum Analysis for {molecule_name} (ALL embeddings) ===\")\n",
    "    \n",
    "    graph_data = next(data for data in all_data if data.name == molecule_name)\n",
    "    graph_data = graph_data.to(device)\n",
    "    \n",
    "    x = graph_data.x.clone().detach().float().to(device)\n",
    "    x.requires_grad = True\n",
    "    baseline = torch.zeros_like(x)\n",
    "    \n",
    "    ig = IntegratedGradients(lambda x, data: embedding_forward_all(x, data).sum(dim=1))  \n",
    "    # sum over embedding dims → scalar output\n",
    "    \n",
    "    attr = ig.attribute(\n",
    "        inputs=x,\n",
    "        baselines=baseline,\n",
    "        additional_forward_args=(graph_data,),\n",
    "        n_steps=50\n",
    "    )  # shape: (num_nodes, num_node_features)\n",
    "    \n",
    "    # Aggregate feature-level attributions per node → scalar signed attribution\n",
    "    node_signed = attr.sum(dim=1).detach().cpu().numpy()\n",
    "    node_magnitude = np.abs(node_signed)\n",
    "    \n",
    "    molecule_node_attributions[molecule_name] = {\n",
    "        'signed': node_signed,\n",
    "        'magnitude': node_magnitude\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.Chem import AllChem\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops\n",
    "import io\n",
    "\n",
    "def trim_white(img):\n",
    "    \"\"\"Crop extra white space around the molecule drawing.\"\"\"\n",
    "    bg = Image.new(img.mode, img.size, (255, 255, 255))\n",
    "    diff = ImageChops.difference(img, bg)\n",
    "    bbox = diff.getbbox()\n",
    "    if bbox:\n",
    "        return img.crop(bbox)\n",
    "    return img\n",
    "\n",
    "# === Modified IG Visualization ===\n",
    "def visualize_combined_molecule(molecule_data, node_attributions, figsize=(800, 800), save_path=None, show=True):\n",
    "    mol = molecule_data.mol\n",
    "    if mol is None:\n",
    "        print(f\"No RDKit molecule available for {molecule_data.name}\")\n",
    "        return\n",
    "    \n",
    "    mol = Chem.Mol(mol)\n",
    "    if mol.GetNumConformers() == 0:\n",
    "        AllChem.Compute2DCoords(mol)\n",
    "    \n",
    "    node_attribute = node_attributions['signed']\n",
    "    # Normalize the IG results to [-1, 1] range after computation\n",
    "    max_abs_val = max(abs(node_attribute.min()), abs(node_attribute.max()))\n",
    "    if max_abs_val > 0:\n",
    "        node_attribute = node_attribute / max_abs_val  # Scale to [-1, 1]\n",
    "    norm = colors.Normalize(vmin=-1, vmax=1)\n",
    "    cmap = plt.colormaps.get_cmap(\"bwr\")  # blue = negative, red = positive\n",
    "    \n",
    "    # Atom colors\n",
    "    atom_colors = {i: cmap(norm(val))[:3] for i, val in enumerate(node_attribute)}\n",
    "    \n",
    "    # Bond colors: average of connected atoms\n",
    "    bond_colors = {}\n",
    "    for bond in mol.GetBonds():\n",
    "        idx1, idx2 = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        avg_val = (node_attribute[idx1] + node_attribute[idx2]) / 2\n",
    "        bond_colors[bond.GetIdx()] = cmap(norm(avg_val))[:3]\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    # Draw molecule with highlights on top\n",
    "    drawer = rdMolDraw2D.MolDraw2DCairo(figsize[0], figsize[1])\n",
    "    opts = drawer.drawOptions()\n",
    "    opts.useBWAtomPalette()\n",
    "    opts.bondLineWidth = 1.5\n",
    "    opts.atomLabelFontSize = 16\n",
    "    opts.highlightColour = (1.0, 1.0, 1.0)  # Make highlights more transparent\n",
    "    opts.fillHighlights = True\n",
    "    opts.highlightsAreCircles = False\n",
    "    \n",
    "    drawer.DrawMolecule(\n",
    "        mol,\n",
    "        highlightAtoms=list(atom_colors.keys()), \n",
    "        highlightAtomColors=atom_colors,\n",
    "        highlightBonds=list(bond_colors.keys()), \n",
    "        highlightBondColors=bond_colors\n",
    "    )\n",
    "    drawer.FinishDrawing()\n",
    "    \n",
    "    png = drawer.GetDrawingText()\n",
    "    image = Image.open(io.BytesIO(png)).convert(\"RGB\")\n",
    "    image = trim_white(image)\n",
    "    \n",
    "    if save_path:\n",
    "        Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if show:\n",
    "        fig, ax = plt.subplots(figsize=(6, 6), dpi=150)\n",
    "        im = ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"{molecule_data.name} — Type: {molecule_data.type}\", pad=25)\n",
    "        \n",
    "        # Add colorbar\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        cbar = plt.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('Signed Attribution', fontsize=12)\n",
    "        # Set major ticks with interval of 0.5\n",
    "        from matplotlib.ticker import MultipleLocator\n",
    "        cbar.ax.xaxis.set_major_locator(MultipleLocator(0.5))\n",
    "        if save_path:\n",
    "            plt.savefig(f\"{save_path}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    return image\n",
    "\n",
    "# === Run visualization ===\n",
    "for molecule_name in molecule_node_attributions:\n",
    "    mol_data = next(d for d in all_data if d.name == molecule_name)\n",
    "    mol_type = mol_data.type\n",
    "    save_path = f\"IntegratedGradients_fig/val/{molecule_name}_{mol_type}\"\n",
    "    \n",
    "    visualize_combined_molecule(\n",
    "        mol_data, \n",
    "        molecule_node_attributions[molecule_name], \n",
    "        save_path=save_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTEGRATED GRADIENT ATTRIBUTION (TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_named_graphs = {}\n",
    "for graph in original_test_data:\n",
    "    name = graph['name']\n",
    "    if name not in unique_named_graphs:\n",
    "        unique_named_graphs[name] = graph\n",
    "unique_graph_list = list(unique_named_graphs.values())\n",
    "mol_loader = DataLoader(unique_graph_list, batch_size=batch_size, shuffle=False)\n",
    "# Execute the EmbeddingsExtractor\n",
    "embedding_generator = EmbeddingsExtractor(model).to(device)\n",
    "embedding_generator.eval()\n",
    "all_embeddings = []\n",
    "all_amines = []\n",
    "all_data = []\n",
    "with torch.no_grad():\n",
    "    for data in mol_loader:\n",
    "        data = data.to(device)\n",
    "        combined_embedding = embedding_generator(data, \n",
    "                                                 include_conditions=False, \n",
    "                                                 extract_embeddings=True)\n",
    "        all_embeddings.append(combined_embedding.cpu())\n",
    "        all_amines.extend(data.name)\n",
    "        all_data.extend(data.cpu().to_data_list())\n",
    "\n",
    "# Now after the loop\n",
    "all_embeddings = torch.cat(all_embeddings)\n",
    "index_to_name = {i: name for i, name in enumerate(all_amines)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def model_output_with_node_input(x_nodes, data):\n",
    "    \"\"\"\n",
    "    Forward wrapper for Captum IG:\n",
    "    - x_nodes: node features (num_nodes x node_dim)\n",
    "    - data: PyG Data object with edge_index, edge_attr, scalars\n",
    "    Returns: tensor of shape [1,1] for a single molecule\n",
    "    \"\"\"\n",
    "    data_modified = data.clone()\n",
    "    data_modified.x = x_nodes\n",
    "\n",
    "    # Ensure scalar features are tensors on the correct device\n",
    "    device = x_nodes.device\n",
    "    data_modified.conc = torch.tensor(data.conc, dtype=torch.float, device=device)\n",
    "    data_modified.temp = torch.tensor(data.temp, dtype=torch.float, device=device)\n",
    "    data_modified.pco2 = torch.tensor(data.pco2, dtype=torch.float, device=device)\n",
    "\n",
    "    out = model(data_modified)  # shape: [1,1]\n",
    "    \n",
    "    # Ensure output has at least 2 dims (batch x output)\n",
    "    if out.dim() == 0:\n",
    "        out = out.unsqueeze(0).unsqueeze(1)\n",
    "    elif out.dim() == 1:\n",
    "        out = out.unsqueeze(0)\n",
    "    \n",
    "    return out\n",
    "\n",
    "# Dictionary to store node-level attributions\n",
    "molecule_node_attributions = {}\n",
    "\n",
    "for molecule_name in [d.name for d in all_data]:\n",
    "    print(f\"\\n=== Captum Analysis for {molecule_name} (Final output) ===\")\n",
    "    \n",
    "    data = next(d for d in all_data if d.name == molecule_name)\n",
    "    data = data.to(device)\n",
    "    \n",
    "    x = data.x.clone().detach().float().to(device)\n",
    "    x.requires_grad = True\n",
    "    \n",
    "    # Zero baseline for node features\n",
    "    baseline = torch.zeros_like(x)\n",
    "    \n",
    "    ig = IntegratedGradients(model_output_with_node_input)\n",
    "    \n",
    "    # Compute IG\n",
    "    attr = ig.attribute(\n",
    "        inputs=x,\n",
    "        baselines=baseline,\n",
    "        additional_forward_args=(data,),\n",
    "        n_steps=50\n",
    "    )  # shape: (num_nodes, num_node_features)\n",
    "    \n",
    "    # Aggregate feature-level attributions per node\n",
    "    node_signed = attr.sum(dim=1).detach().cpu().numpy()      # signed attributions\n",
    "    node_magnitude = np.abs(node_signed)                     # magnitude\n",
    "    \n",
    "    molecule_node_attributions[molecule_name] = {\n",
    "        'signed': node_signed,\n",
    "        'magnitude': node_magnitude\n",
    "    }\n",
    "\n",
    "    print(f\"Node attributions (signed): {node_signed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.Chem import AllChem\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops\n",
    "import io\n",
    "\n",
    "def trim_white(img):\n",
    "    \"\"\"Crop extra white space around the molecule drawing.\"\"\"\n",
    "    bg = Image.new(img.mode, img.size, (255, 255, 255))\n",
    "    diff = ImageChops.difference(img, bg)\n",
    "    bbox = diff.getbbox()\n",
    "    if bbox:\n",
    "        return img.crop(bbox)\n",
    "    return img\n",
    "\n",
    "# === Modified IG Visualization ===\n",
    "def visualize_combined_molecule(molecule_data, node_attributions, figsize=(800, 800), save_path=None, show=True):\n",
    "    mol = molecule_data.mol\n",
    "    if mol is None:\n",
    "        print(f\"No RDKit molecule available for {molecule_data.name}\")\n",
    "        return\n",
    "    \n",
    "    mol = Chem.Mol(mol)\n",
    "    if mol.GetNumConformers() == 0:\n",
    "        AllChem.Compute2DCoords(mol)\n",
    "    \n",
    "    node_attribute = node_attributions['signed']\n",
    "    # Normalize the IG results to [-1, 1] range after computation\n",
    "    max_abs_val = max(abs(node_attribute.min()), abs(node_attribute.max()))\n",
    "    if max_abs_val > 0:\n",
    "        node_attribute = node_attribute / max_abs_val  # Scale to [-1, 1]\n",
    "    norm = colors.Normalize(vmin=-1, vmax=1)\n",
    "    cmap = plt.colormaps.get_cmap(\"bwr\")  # blue = negative, red = positive\n",
    "    \n",
    "    # Atom colors\n",
    "    atom_colors = {i: cmap(norm(val))[:3] for i, val in enumerate(node_attribute)}\n",
    "    \n",
    "    # Bond colors: average of connected atoms\n",
    "    bond_colors = {}\n",
    "    for bond in mol.GetBonds():\n",
    "        idx1, idx2 = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        avg_val = (node_attribute[idx1] + node_attribute[idx2]) / 2\n",
    "        bond_colors[bond.GetIdx()] = cmap(norm(avg_val))[:3]\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    \n",
    "    # Draw molecule with highlights on top\n",
    "    drawer = rdMolDraw2D.MolDraw2DCairo(figsize[0], figsize[1])\n",
    "    opts = drawer.drawOptions()\n",
    "    opts.useBWAtomPalette()\n",
    "    opts.bondLineWidth = 1.5\n",
    "    opts.atomLabelFontSize = 16\n",
    "    opts.highlightColour = (1.0, 1.0, 1.0)  # Make highlights more transparent\n",
    "    opts.fillHighlights = True\n",
    "    opts.highlightsAreCircles = False\n",
    "    \n",
    "    drawer.DrawMolecule(\n",
    "        mol,\n",
    "        highlightAtoms=list(atom_colors.keys()), \n",
    "        highlightAtomColors=atom_colors,\n",
    "        highlightBonds=list(bond_colors.keys()), \n",
    "        highlightBondColors=bond_colors\n",
    "    )\n",
    "    drawer.FinishDrawing()\n",
    "    \n",
    "    png = drawer.GetDrawingText()\n",
    "    image = Image.open(io.BytesIO(png)).convert(\"RGB\")\n",
    "    image = trim_white(image)\n",
    "    \n",
    "    if save_path:\n",
    "        Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if show:\n",
    "        fig, ax = plt.subplots(figsize=(6, 6), dpi=150)\n",
    "        im = ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"{molecule_data.name} — Type: {molecule_data.type}\", pad=25)\n",
    "        \n",
    "        # Add colorbar\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        cbar = plt.colorbar(sm, ax=ax, orientation='horizontal', fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('Signed Attribution', fontsize=12)\n",
    "        # Set major ticks with interval of 0.5\n",
    "        from matplotlib.ticker import MultipleLocator\n",
    "        cbar.ax.xaxis.set_major_locator(MultipleLocator(0.5))\n",
    "        if save_path:\n",
    "            plt.savefig(f\"{save_path}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    return image\n",
    "\n",
    "# === Run visualization ===\n",
    "for molecule_name in molecule_node_attributions:\n",
    "    mol_data = next(d for d in all_data if d.name == molecule_name)\n",
    "    mol_type = mol_data.type\n",
    "    save_path = f\"IntegratedGradients_fig/test/{molecule_name}_{mol_type}\"\n",
    "    \n",
    "    visualize_combined_molecule(\n",
    "        mol_data, \n",
    "        molecule_node_attributions[molecule_name], \n",
    "        save_path=save_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BACKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import numpy as np\n",
    "if not hasattr(np, \"bool\"):\n",
    "    np.bool = np.bool_\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Stack all embeddings into a 2D array (num_molecules x 64)\n",
    "embeddings = np.stack([d.embedding if isinstance(d.embedding, np.ndarray) else d.embedding.numpy()\n",
    "                       for d in unique_graph_list_with_embeddings])\n",
    "\n",
    "# Step 2: Compute correlation matrix (64 x 64)\n",
    "corr_matrix = np.corrcoef(embeddings, rowvar=False)\n",
    "\n",
    "# Step 3: Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', center=0, square=True)\n",
    "plt.xlabel(\"Embedding Dimension\")\n",
    "plt.ylabel(\"Embedding Dimension\")\n",
    "plt.show()\n",
    "# Extract off-diagonal correlations\n",
    "off_diag_corrs = corr_matrix[np.triu_indices_from(corr_matrix, k=1)]\n",
    "\n",
    "# Test against null hypothesis of orthogonality (mean ≈ 0)\n",
    "from scipy import stats\n",
    "t_stat, p_value = stats.ttest_1samp(off_diag_corrs, 0)\n",
    "\n",
    "# Also check distribution statistics\n",
    "print(f\"Mean absolute correlation: {np.mean(np.abs(off_diag_corrs)):.3f}\")\n",
    "print(f\"Std of correlations: {np.std(off_diag_corrs):.3f}\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Quick significance test you can run:\n",
    "from scipy import stats\n",
    "\n",
    "# Test if mean significantly different from orthogonal (0)\n",
    "t_stat, p_value = stats.ttest_1samp(np.abs(off_diag_corrs), 0)\n",
    "print(f\"P-value for non-orthogonality: {p_value}\")\n",
    "\n",
    "# Also check what fraction are \"strong\" correlations\n",
    "strong_corr_fraction = np.mean(np.abs(off_diag_corrs) > 0.3)\n",
    "print(f\"Fraction with |r| > 0.3: {strong_corr_fraction:.2%}\") \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
